{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io as io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TensorFlow and enable eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_ROOT = '/data/COCO/'\n",
    "CKPT_DIR = 'logs/person_coco_aspp/ckpt'\n",
    "THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import COCO API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, os.path.join(COCO_ROOT, 'cocoapi/PythonAPI'))\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load COCO image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of images: 2693\n"
     ]
    }
   ],
   "source": [
    "ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_val2017.json')\n",
    "coco = COCO(ann_file_fpath)\n",
    "cat_ids = coco.getCatIds(catNms=['person'])\n",
    "img_list = coco.getImgIds(catIds=cat_ids)\n",
    "print('Number of images: {}'.format(len(img_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to encode segmentation map using RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rle(mask):\n",
    "    mask_flat = mask.flatten('F')\n",
    "    flag = 0\n",
    "    rle_list = list()\n",
    "    for i in range(mask_flat.shape[0]):\n",
    "        if flag == 0:\n",
    "            if mask_flat[i] == 1:\n",
    "                flag = 1\n",
    "                starts = i+1\n",
    "                rle_list.append(starts)\n",
    "        else:\n",
    "            if mask_flat[i] == 0:\n",
    "                flag = 0\n",
    "                ends = i\n",
    "                rle_list.append(ends-starts+1)\n",
    "    if flag == 1:\n",
    "        ends = mask_flat.shape[0]\n",
    "        rle_list.append(ends-starts+1)\n",
    "    #sanity check\n",
    "    if len(rle_list) % 2 != 0:\n",
    "        print('NG')\n",
    "    if len(rle_list) == 0:\n",
    "        rle = np.nan\n",
    "    else:\n",
    "        rle = ' '.join(map(str,rle_list))\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and restore from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7f664a05c2e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model\n",
    "net = model.Model()\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=net)\n",
    "ckpt.restore(tf.train.latest_checkpoint(CKPT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(img):\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.tile(img[..., None], (1, 1, 3))\n",
    "    img = img[None, ...].astype(np.float32) / np.float32(255.)\n",
    "    \n",
    "    img640 = np.zeros([1, 640, 640, 3], np.float32)\n",
    "    img640[:, :img.shape[1], :img.shape[2], :] = img\n",
    "\n",
    "    logits = net(img640, is_training=False)\n",
    "    img_out = tf.sigmoid(logits).numpy()\n",
    "    \n",
    "    mask_out = (img_out[0, :, :, 0] > THRESHOLD).astype(np.uint8)\n",
    "    mask_out = mask_out[:img.shape[1], :img.shape[2]]\n",
    "    \n",
    "    return mask_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on all test images and encode the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : val2017/000000532481.jpg\n",
      "WARNING:tensorflow:From /home/dkorobchenko/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "10 : val2017/000000401446.jpg\n",
      "20 : val2017/000000475191.jpg\n",
      "30 : val2017/000000122962.jpg\n",
      "40 : val2017/000000442480.jpg\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "submit_name_arr = list()\n",
    "submit_rle_arr = list()\n",
    "\n",
    "for counter, img_id in enumerate(img_list):\n",
    "    img_data = coco.loadImgs(img_id)[0]\n",
    "    img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
    "    \n",
    "    if counter % 10 == 0:\n",
    "        print('{} : {}'.format(counter, img_fname))\n",
    "        \n",
    "    img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
    "    mask_out = inference(img)\n",
    "\n",
    "    rle = mask_to_rle(mask_out)\n",
    "\n",
    "    submit_name_arr.append(img_fname)\n",
    "    submit_rle_arr.append(rle)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pandas DataFrame and save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val2017/000000532481.jpg</td>\n",
       "      <td>116073 1 116498 2 116923 4 117348 6 117774 7 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val2017/000000458755.jpg</td>\n",
       "      <td>14009 1 14487 4 14966 5 14988 2 15445 6 15466 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val2017/000000385029.jpg</td>\n",
       "      <td>2329 10 2809 11 3289 12 3769 13 4249 13 4728 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val2017/000000311303.jpg</td>\n",
       "      <td>11938 1 12365 1 12792 1 13219 1 13646 1 14073 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val2017/000000393226.jpg</td>\n",
       "      <td>46405 3 46881 10 47358 14 47836 17 48313 21 48...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ImageId                                      EncodedPixels\n",
       "0  val2017/000000532481.jpg  116073 1 116498 2 116923 4 117348 6 117774 7 1...\n",
       "1  val2017/000000458755.jpg  14009 1 14487 4 14966 5 14988 2 15445 6 15466 ...\n",
       "2  val2017/000000385029.jpg  2329 10 2809 11 3289 12 3769 13 4249 13 4728 1...\n",
       "3  val2017/000000311303.jpg  11938 1 12365 1 12792 1 13219 1 13646 1 14073 ...\n",
       "4  val2017/000000393226.jpg  46405 3 46881 10 47358 14 47836 17 48313 21 48..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df = pd.DataFrame(OrderedDict({\n",
    "    'ImageId': submit_name_arr,\n",
    "    'EncodedPixels': submit_rle_arr,\n",
    "}))\n",
    "\n",
    "submit_df.to_csv('submit.csv', index=False)\n",
    "\n",
    "submit_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
